
---
title: "Legionella case_match incubation delay"
author: "Kelsie Cassell"
date: '2022-09-23'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
library(dplyr)
library(reshape2)
library(rjags)
library(stringr)
library(gtools)
#install.packages("hydroTSM")
library(HDInterval)
library(hydroTSM)
library(data.table)
```


Build a case set that looks like a true LD case set in Connecticut
Try this again with 2017 and 2018 data to see fit 

``` {r}
weather.d = read.csv("./Data/CONFIDENTIAL/observed_ts.csv") %>%
  mutate(dates = as.Date(symptom_date, '%m/%d/%Y')) %>%
  select(dates, rain0)

```

once we get to half an inch per day then it's easier to tease apart the 6-8 day lag from the rain1 and two day lag 
Still shows that 14 day lag 

Above ^^ the model is able to select lag days 6 and 7 as the best fit (however other days also have high coeff - like lag day 9)

So here I'm assigning rain_weights to primarily days 6 and 7 to reflect what's seen in the case data too. 
``` {r}
# weather.d <- weather.d[,1:10]
# subset to 2017 
#weather.d$rain0 = ifelse(weather.d$rain0 > 0.25, 1, 0)

w.2017 = weather.d %>%
  mutate( rain1 = lag(rain0,1),
          rain2 = lag(rain0,2),
          rain3 = lag(rain0,3),
          rain4 = lag(rain0,4),
          rain5 = lag(rain0,5),
          rain6 = lag(rain0,6),
          rain7 = lag(rain0,7),
          rain8 = lag(rain0,8),
          rain9 = lag(rain0,9),
          rain10 = lag(rain0,10),
         rain11 = lag(rain0,11),
         rain12 = lag(rain0,12),
         rain13 = lag(rain0,13),
         rain14 = lag(rain0,14),
         rain15 = lag(rain0,15),
         rain16 = lag(rain0,16),
         rain17 = lag(rain0,17),
         rain18 = lag(rain0,18),
         rain19 = lag(rain0,19),
         rain20 = lag(rain0,20),
          year=year(dates)
          ) %>%
  filter(year %in% c(2012, 2013, 2014, 2015, 2016,2017,2018)) %>%
  select(dates,starts_with('rain')) %>%
  filter(!is.na(rain20))



rain_weights <- c(0,0, 1, 0, 0.0,0.0,0.0,0.0,0,0,0,0,0,0,0,0,0,0,0,0,0) 
rain_composite = as.matrix(w.2017[,-1]) %*% rain_weights

set.seed(123)

rain_comp_weight = 2 # this helps model fitting below. 

df1  <- w.2017 %>%
  mutate(t=row_number(),
         sin1= 2*sin(2*pi*t/365),
         cos1= 2*cos(2*pi*t/365),

         N_exposures = rpois(length(dates), ( exp(-2 + 0.03*sin1) + rain_composite*rain_comp_weight ) ) 
         )


plot(df1$N_exposures, type = 'l', main = 'Generated case data')


plot(w.2017$rain0, type = 'l', main = 'CT rainfall data')


```


Now use the simulated data in a basic dist lag model of association between exposure and rainfall
```{r}
# weather.d
# when I use real weather data it seems like it's off by one day each time? 


mod1 <- glm(N_exposures ~ rain0 + rain1 + rain2 + rain3 + rain4 + rain5 + rain6 + rain7 + rain8 + rain9 , data=df1, family=gaussian(link='identity'))

summary(mod1)
#coefs_rain <- coef(mod1)[-c(1,2,3)]
coefs_rain <- coef(mod1)[grep('rain',names(coef(mod1)))] 

plot(coefs_rain)
points(rain_comp_weight*rain_weights, col='red')

plot(cumsum(coefs_rain))
points(cumsum(rain_comp_weight*rain_weights) ,col='red')


plot(coefs_rain,rain_comp_weight*rain_weights[1:10])



```


Test out JAGS model using the full case dataset then 
```{r}
x <- seq(0, 20, by=1)
delay_dist = dgamma(x, shape = 4.96, scale = 1.27, log = FALSE)
delay_dist <- delay_dist/sum(delay_dist)
plot(delay_dist, type = 'l')
#rmultinom(1,100,delay_dist)

r1 <- rgamma(1000,shape = 4.96, scale = 1.27)

```



Generate some case data based on three years of generated weather data 
```{r}
set.seed(1234)
df1 = df1[complete.cases(df1),]

dist_data <- t(sapply(df1$N_exposures, function(x) rmultinom(1,x,delay_dist)))

df2 <- cbind.data.frame('dates'=df1$dates, dist_data)

# Reshape the date into long format, determine the symptom onset date based on exposure date + delay, then sum by symptom onset date to get 'observed' time series
observed_ts <- reshape2::melt(df2, id.vars='dates') %>%
  rename(exposure_date=dates) %>%
  mutate(delay = as.numeric(as.character(variable)),
         symptom_date= exposure_date + delay - 1) %>%
  group_by(symptom_date) %>%
  summarize(N_cases=sum(value))

observed_ts <- merge(observed_ts, df1, by.x='symptom_date', by.y='dates')

observed_ts$sin1 = cos(2*pi*observed_ts$t/365)
observed_ts$cos1 = cos(2*pi*observed_ts$t/365)

#observed_ts = merge(observed_ts,w.2017, by.y = 'dates', by.x = 'symptom_date', all.x = T)

plot(observed_ts$symptom_date, observed_ts$N_cases, type='l', main='N', bty='l')

```

## Simple model of rainfall and reported cases
take rainfall data, and combine together with the latent distribution, use lags of this on case data. This makes it so that we don't need to explicitly construct the latent exposure variable

The coefficient
```{r}

rain_lags <- df1 %>%
  select(starts_with('rain'))

observed_ts$latent_rf <- as.matrix(rain_lags) %*% delay_dist #latent rainfall

observed_ts <- observed_ts %>%
  mutate( latent_rf1 = lag(latent_rf,1),
          latent_rf2 = lag(latent_rf,2),
          latent_rf3 = lag(latent_rf,3),
          latent_rf4 = lag(latent_rf,4),
          latent_rf5 = lag(latent_rf,5),
          latent_rf6 = lag(latent_rf,6),
          latent_rf7 = lag(latent_rf,7),
          latent_rf8 = lag(latent_rf,8),
          latent_rf9 = lag(latent_rf,9),
          latent_rf10 = lag(latent_rf,10),
          latent_rf11 = lag(latent_rf,11),
          latent_rf12 = lag(latent_rf,12),
          latent_rf13 = lag(latent_rf,13),
          latent_rf14 = lag(latent_rf,14),
          latent_rf15 = lag(latent_rf,15),
          latent_rf16 = lag(latent_rf,16),
          latent_rf17 = lag(latent_rf,17),
          latent_rf18 = lag(latent_rf,18),
          
          )

mod2 <- glm(N_cases  ~ latent_rf + latent_rf1 + latent_rf2      , data=observed_ts, family=poisson(link='identity'))
summary(mod2)

coef2 <- coefficients(mod2)[-1]

plot(coef2)
```


Can skip this and use a simpler regression by:
-create a matrix of rainfall with lags (lag0, lag1, lag2...)
-Multiply this by the clinical delay distribution to relate exposures to cases
-Then evaluate lags of this new rainfall variable with observed cases
-I think this is equivalent to what we have below IF you have an additive model



AR component: 
 log.beta[1] ~ dnorm(0,(1-rho3^2)*tau3.beta)
 for(i in 2:15){
  log.beta[i] ~ dnorm(rho3*beta[i-1], tau3.beta) #AR(1) model
 }
 

```{r}
model_string <- "
model{
for(t in 37:N_times){ #22 lag from linking epsilon to lambda, and 10 lag from linking rainfall to epsilon
  N_cases[t] ~ dpois(lambda[t])
  
  lambda[t] <- (epsilon[t]*delay_dist[1] + 
               epsilon[t- 1 ]*delay_dist[2] + 
               epsilon[t- 2 ]*delay_dist[3] +
               epsilon[t- 3 ]*delay_dist[4] + 
               epsilon[t- 4 ]*delay_dist[5] +
               epsilon[t- 5 ]*delay_dist[6] + 
               epsilon[t- 6 ]*delay_dist[7] +
               epsilon[t- 7 ]*delay_dist[8] + 
               epsilon[t- 8 ]*delay_dist[9] +
               epsilon[t- 9 ]*delay_dist[10] + 
               epsilon[t- 10 ]*delay_dist[11] +
               epsilon[t- 11 ]*delay_dist[12] + 
               epsilon[t- 12 ]*delay_dist[13] +
               epsilon[t- 13 ]*delay_dist[14] + 
               epsilon[t- 14 ]*delay_dist[15] +
               epsilon[t- 15 ]*delay_dist[16] + 
               epsilon[t- 16 ]*delay_dist[17] +
               epsilon[t- 17 ]*delay_dist[18] +
               epsilon[t- 18 ]*delay_dist[19] +
               epsilon[t- 19 ]*delay_dist[20] +
               epsilon[t- 20 ]*delay_dist[21] )
            
} 
  for(t in 15:N_times){
      epsilon[t] <- exp(int + sin365[t]*delta[1] + cos365[t]*delta[2] + rain[t]*beta[1] +  rain[t-1]*beta[2]  +   rain[t-2]*beta[3]
       +  rain[t-3]*beta[4] +  rain[t-4]*beta[5] +  rain[t-5]*beta[6] +  rain[t-6]*beta[7] +  rain[t-7]*beta[8]
        +  rain[t-8]*beta[9] +  rain[t-9]*beta[10] + rain[t-10]*beta[11]  + rain[t-11]*beta[12] + rain[t-12]*beta[13] 
        + rain[t-13]*beta[14] + rain[t-14]*beta[15] )  
        
  }
   int ~ dnorm(0, 1e-4)
   
 log.beta[1] ~ dnorm(0,(1-rho3^2)*tau3.beta)
 for(i in 2:15){
  log.beta[i] ~ dnorm(rho3*beta[i-1], tau3.beta) #AR(1) model
 }
 
 for(i in 1:15){
    beta[i] <- exp(log.beta[i])
 }
   for(i in 1:2){
  delta[i] ~ dnorm(0, 1e-4) 
   }

    tau3.beta ~ dgamma(3,2)
    
    rho3 ~ dunif (-1,1)
}
"
# the betas are logged to make sure they're positive 
##############################################################
#Model Fitting
##############################################################
inits1=list(".RNG.seed"=c(123), ".RNG.name"='base::Wichmann-Hill')
inits2=list(".RNG.seed"=c(456), ".RNG.name"='base::Wichmann-Hill')
inits3=list(".RNG.seed"=c(789), ".RNG.name"='base::Wichmann-Hill')
##############################################
#Model Organization
##############################################

model_spec<-textConnection(model_string)
model_jags<-jags.model(model_spec, 
                       inits=list(inits1,inits2, inits3),
                       data=list('N_cases'= observed_ts$N_cases,
                                  # 'N_times'= 355, #could use whole dataset but would take a long time
                                  'N_times'= 1000, #nrow(observed_ts), #could use whole dataset but would take a long time
                                                       'delay_dist'=delay_dist,
                                 'sin365' = observed_ts$sin1,
                                 'cos365' = observed_ts$cos1,
                                 'rain'= observed_ts$rain0
                                    ),
                       n.adapt=5000, # normally 10000
                       n.chains=3)
params<-c('lambda', 'beta', 'delta','epsilon', 'rho3','tau3.beta', 'int')
##############################################
#Posterior Sampling
##############################################
posterior_samples<-coda.samples(model_jags, 
                                params, 
                                n.iter=5000) # usually 10000
posterior_samples.all<-do.call(rbind,posterior_samples)
#post1.summary<-summary(posterior_samples)
#post_means<-colMeans(posterior_samples.all)
post_means<-apply(posterior_samples.all, 2, mean)
sample.labs<-names(post_means)
ci<-t(hdi(posterior_samples.all, credMass = 0.95))
#ci<-matrix(sprintf("%.1f",round(ci,1)), ncol=2)
ci<-matrix(ci, ncol=2)
row.names(ci)<-sample.labs
#post_means<-sprintf("%.1f",round(post_means,1))
names(post_means)<-sample.labs
indices <- str_extract_all(names(post_means), "(?<=\\[).+?(?=\\])")
rep1 <- sapply(indices, function(x) identical(x, character(0))) #is it missing ie character(0)
indices[which(rep1==1)] <- '999'
index_n <- as.numeric(unlist(indices))
combined <- cbind.data.frame(post_means, ci,index_n )
names(combined) <- c('mean','lcl','ucl','index_t')
post_epsilon <- combined[grep('epsilon',names(post_means)),]
post_lambda <- combined[grep('lambda',names(post_means)),]
#model vs observed TS
plot(test$case_sum[1:1095], type='l')
points(post_epsilon$index_t, post_epsilon$mean, type='l' ,col='red')
points(post_lambda$index_t,post_lambda$mean, type='l' ,col='blue')
#model vs true exposure TS
plot(test$case_sum[1:1095], type='l')
points(post_epsilon$index_t, post_epsilon$mean, type='l' ,col='red')
points(post_lambda$index_t,post_lambda$mean, type='l' ,col='blue')
# saveRDS(posterior_samples.all,'./Results/posteriors.rds')
```

```{r}
str(posterior_samples.all)
plot(posterior_samples.all[,"beta[1]"], type='l')
plot(posterior_samples.all[,"int"], type='l')
plot(posterior_samples.all[,"rho3"], type='l')
plot(posterior_samples.all[,"beta[2]"],posterior_samples.all[,"rho3"])
```

```{r}
par(mfrow = c(1,1))
post_beta <- combined[grep('beta[',names(post_means), fixed=T),]
 plot(cumsum(rain_weights), type='l')
 points(cumsum(post_beta$mean), type='l', col='red')
plot(post_beta$mean, type='l', col='red')
points(post_beta$lcl, type='l', col='red', lty=3)
points(post_beta$ucl, type='l', col='red', lty=3)
points(rain_weights, type='l')

post_beta$mean
post_beta$lcl
post_beta$ucl
post_beta$ucl- (1 - post_beta$lcl)
```

```{r}
beta_samps <- posterior_samples.all[0001:5000,grep('beta[',names(post_means), fixed=T)]
matplot(t(beta_samps/rain_comp_weight), type='l', ylim=c(-0.1, 0.3))
points(rain_weights, type='l')
```


Posteriors
```{r}
plot(posterior_samples.all[,'alpha[35]'], type='l')
plot(posterior_samples.all[,'lambda[35]'], type='l')
#plot(posterior_samples.all[,'delay_est[10]'], type='l')
plot(posterior_samples.all[,'beta[4]'], type='l')
```

```{r}
post_delay_est <- combined[grep('delay_est',names(post_means)),]
plot(post_delay_est$mean, type='l', ylim=c(0,1))
points(delay_dist, type='l', lty=2, lwd=2, col='red')
post_samples_delay <- posterior_samples.all[,grep('delay_est',names(post_means))]
apply(post_samples_delay[1:100,],1,sum)
matplot(t(post_samples_delay[1:2000,]), type='l')
points(delay_dist, col='red', lwd=2, lty=2, type='l')
```









































