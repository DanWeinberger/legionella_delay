
---
title: "Legionella case_match incubation delay"
author: "Kelsie Cassell"
date: '2022-09-23'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
library(dplyr)
library(reshape2)
library(rjags)
library(stringr)
library(gtools)
#install.packages("hydroTSM")
library(HDInterval)
library(hydroTSM)
library(data.table)
```


Build a case set that looks like a true LD case set in Connecticut
Try this again with 2017 and 2018 data to see fit 

``` {r}
weather.d = read.csv("./Data/CONFIDENTIAL/observed_ts.csv") %>%
  mutate(dates = as.Date(symptom_date, '%m/%d/%Y')) %>%
  select(dates, rain0)

```

once we get to half an inch per day then it's easier to tease apart the 6-8 day lag from the rain1 and two day lag 
Still shows that 14 day lag 

Above ^^ the model is able to select lag days 6 and 7 as the best fit (however other days also have high coeff - like lag day 9)

So here I'm assigning rain_weights to primarily days 6 and 7 to reflect what's seen in the case data too. 
``` {r}
# weather.d <- weather.d[,1:10]
# subset to 2017 
#weather.d$rain0 = ifelse(weather.d$rain0 > 0.25, 1, 0)

w.2017 = weather.d %>%
  mutate( rain0 = rain0/sd(rain0),
          rain1 = lag(rain0,1),
          rain2 = lag(rain0,2),
          rain3 = lag(rain0,3),
          rain4 = lag(rain0,4),
          rain5 = lag(rain0,5),
          rain6 = lag(rain0,6),
          rain7 = lag(rain0,7),
          rain8 = lag(rain0,8),
          rain9 = lag(rain0,9),
          rain10 = lag(rain0,10),
         rain11 = lag(rain0,11),
         rain12 = lag(rain0,12),
         rain13 = lag(rain0,13),
         rain14 = lag(rain0,14),
         rain15 = lag(rain0,15),
         rain16 = lag(rain0,16),
         rain17 = lag(rain0,17),
         rain18 = lag(rain0,18),
         rain19 = lag(rain0,19),
         rain20 = lag(rain0,20),
          year=year(dates)
          ) %>%
  filter(year %in% c(2012, 2013, 2014, 2015, 2016,2017,2018)) %>%
  select(dates,starts_with('rain')) %>%
  filter(!is.na(rain20))



rain_weights <- c(0,0, 0, 0, 0.00, 1/3, 1/3, 1/3, 0.00, 0,0,0,0,0,0,0,0,0,0,0,0) 
rain_composite = as.matrix(w.2017[,-1]) %*% rain_weights

set.seed(123)

rain_comp_weight = 1.3 # this helps model fitting below. 

df1  <- w.2017 %>%
  mutate(t=row_number(),
         sin1= 2*sin(2*pi*t/365),
         cos1= 2*cos(2*pi*t/365),

         N_exposures = rpois(length(dates), ( exp(-2 + 0.3*sin1) + rain_composite*rain_comp_weight ) ) 
         )


plot(df1$N_exposures, type = 'l', main = 'Generated case data')


plot(w.2017$rain0, type = 'l', main = 'CT rainfall data')


```


Now use the simulated data in a basic dist lag model of association between exposure and rainfall
```{r}
# weather.d
# when I use real weather data it seems like it's off by one day each time? 


mod1 <- glm(N_exposures ~ rain0 + rain1 + rain2 + rain3 + rain4 + rain5 + rain6 + rain7 + rain8 + rain9 , data=df1, family=gaussian(link='identity'))

summary(mod1)
#coefs_rain <- coef(mod1)[-c(1,2,3)]
coefs_rain <- coef(mod1)[grep('rain',names(coef(mod1)))] 

plot(coefs_rain)
points(rain_comp_weight*rain_weights, col='red')

plot(cumsum(coefs_rain))
points(cumsum(rain_comp_weight*rain_weights) ,col='red')


plot(coefs_rain,rain_comp_weight*rain_weights[1:10])



```


Test out JAGS model using the full case dataset then 
```{r}
x <- seq(0, 20, by=1)
delay_dist = dgamma(x, shape = 4.96, scale = 1.27, log = FALSE)
delay_dist <- delay_dist/sum(delay_dist)
plot(delay_dist, type = 'l')
#rmultinom(1,100,delay_dist)

r1 <- rgamma(1000,shape = 4.96, scale = 1.27)

```



Generate some case data based on three years of generated weather data 
```{r}
set.seed(1234)
df1 = df1[complete.cases(df1),]

dist_data <- t(sapply(df1$N_exposures, function(x) rmultinom(1,x,delay_dist)))

df2 <- cbind.data.frame('dates'=df1$dates, dist_data)

# Reshape the date into long format, determine the symptom onset date based on exposure date + delay, then sum by symptom onset date to get 'observed' time series
observed_ts <- reshape2::melt(df2, id.vars='dates') %>%
  rename(exposure_date=dates) %>%
  mutate(delay = as.numeric(as.character(variable)),
         symptom_date= exposure_date + delay - 1) %>%
  group_by(symptom_date) %>%
  summarize(N_cases=sum(value))

observed_ts <- merge(observed_ts, df1, by.x='symptom_date', by.y='dates')

observed_ts$sin1 = cos(2*pi*observed_ts$t/365)
observed_ts$cos1 = cos(2*pi*observed_ts$t/365)

#observed_ts = merge(observed_ts,w.2017, by.y = 'dates', by.x = 'symptom_date', all.x = T)

plot(observed_ts$symptom_date, observed_ts$N_cases, type='l', main='N', bty='l')

```

## Maximum likelihood model

```{r}

Xvars <- observed_ts %>%
  mutate(intercept=1) %>%
  select(intercept,sin1,cos1,starts_with('rain')) %>%
  as.matrix()

delay_dist = dgamma(x, shape = 4.96, scale = 1.27, log = FALSE)
delay_dist <- delay_dist/sum(delay_dist)


LogLike <- function(dat,par,  X=Xvars, delay_dist) {

  beta <- exp(par)
  beta[2:3] <- par[2:3] #effect of sine/cosine can be negative or positive
  
  # lm( epsilon ~ 1 + sin1 + cos1 + rain0 +rain1...)
  epsilon <-  X %*% beta  #linear  
  
  epsilon.mat <- as.data.frame(epsilon) %>%
     mutate(epsilon1=lag(epsilon,1),
            epsilon2=lag(epsilon,2),
            epsilon3=lag(epsilon,3),
            epsilon4=lag(epsilon,4),
            epsilon5=lag(epsilon,5),
            epsilon6=lag(epsilon,6),
            epsilon7=lag(epsilon,7),
            epsilon8=lag(epsilon,8),
            epsilon9=lag(epsilon,9),
            epsilon10=lag(epsilon,10),
            epsilon11=lag(epsilon,11),
            epsilon12=lag(epsilon,12),
            epsilon13=lag(epsilon,13),
            epsilon14=lag(epsilon,14),
            epsilon15=lag(epsilon,15),
            epsilon16=lag(epsilon,16),
            epsilon17=lag(epsilon,17),
            epsilon18=lag(epsilon,18),
            epsilon19=lag(epsilon,19),
            epsilon20=lag(epsilon,20)
            ) %>%
    as.matrix()
  
    lambda <- epsilon.mat %*% delay_dist
    
    min.lambda <- min(lambda, na.rm=T)
    
    if(min(lambda, na.rm=T) >0){
       LL <- -sum(dpois(dat$N_cases[-c(1:21)], lambda[-c(1:21)], log = TRUE))
     }else{
       LL <- 99999999 
     }
    return(LL)
}

parms <- rnorm(ncol(Xvars),0,0.001)

m.like = optim(par = parms, fn = LogLike, dat = observed_ts, X=Xvars, delay_dist=delay_dist, method='BFGS')

#m.like = nloptr::nloptr(x0 = parms, eval_f = LogLike, dat = observed_ts, X=Xvars, delay_dist=delay_dist,opts = list("algorithm"="NLOPT_LN_COBYLA"))

m.like

if(m.like$convergence==0){
  print('CONVERGED')
}else{
  print('NOT-converged')
}

parms <- m.like$par
names(parms) <- colnames(Xvars)


parms.rain <-exp(parms[grep('rain', names(parms))])

plot(parms.rain)
points(rain_weights*rain_comp_weight, col='red')

plot(cumsum(parms.rain))
points(cumsum(rain_weights*rain_comp_weight), col='red')
```















